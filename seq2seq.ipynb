{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Sequence to Sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T03:14:50.359769Z",
     "start_time": "2019-04-22T03:14:49.467928Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import time\n",
    "from mxnet import nd, init, gluon, autograd\n",
    "from mxnet.gluon import nn, rnn, loss as gloss\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class TwoSeqEncoder(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(TwoSeqEncoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = rnn.LSTM(num_hiddens, num_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, left_input, right_input, *args):\n",
    "        X_left = self.embedding(left_input) # X shape: (batch_size, seq_len, embed_size)\n",
    "        X_left = X_left.swapaxes(0, 1)  # RNN needs first axes to be time\n",
    "        left_state = self.rnn.begin_state(batch_size=X_left.shape[1], \\\n",
    "                                               ctx=X_left.context)\n",
    "        left_out, left_state = self.rnn(X_left, left_state)\n",
    "        X_right = self.embedding(right_input) # X shape: (batch_size, seq_len, embed_size)\n",
    "        X_right = X_right.swapaxes(0, 1)  # RNN needs first axes to be time\n",
    "        right_state = self.rnn.begin_state(batch_size=X_right.shape[1], \\\n",
    "                                               ctx=X_right.context)\n",
    "        right_out, right_state = self.rnn(X_right, right_state)\n",
    "        # The shape of out is (seq_len, batch_size, num_hiddens).\n",
    "        # state contains the hidden state and the memory cell\n",
    "        # of the last time step, the shape is (num_layers, batch_size, num_hiddens)\n",
    "        return left_out, right_out, left_state, right_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sanity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 4, 16), 2, (2, 4, 16), (2, 4, 16))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TwoSeqEncoder(vocab_size=10, embed_size=8,\n",
    "                         num_hiddens=16, num_layers=2)\n",
    "encoder.initialize()\n",
    "X = nd.zeros((4, 7))\n",
    "left_output, right_output, left_state, right_state = encoder(X, X)\n",
    "# after running the encoder, output and state are both a list\n",
    "# which contains the whole output and state of each time state in history\n",
    "left_output.shape, len(right_state), left_state[0].shape, right_state[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManhattanDistance(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ExtractLastState, self).__init__(**kwargs)\n",
    "    \n",
    "    def forward(self, left_output, right_output, left_state, right_state):\n",
    "        left_embed = left_state[-1]\n",
    "        right_embed = right_state[-1]\n",
    "        return nd.exp(-nd.sum(nd.abs(left_embed-right_embed), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch7(model, data_iter, lr, num_epochs, ctx):  # Saved in d2l\n",
    "    model.initialize(init.Xavier(), force_reinit=True, ctx=ctx)\n",
    "    trainer = gluon.Trainer(model.collect_params(),\n",
    "                            'adam', {'learning_rate': lr})\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    tic = time.time()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        l_sum, num_tokens_sum = 0.0, 0.0\n",
    "        for batch in data_iter:\n",
    "            X, X_vlen, Y, Y_vlen = [x.as_in_context(ctx) for x in batch]\n",
    "            Y_input, Y_label, Y_vlen = Y[:,:-1], Y[:,1:], Y_vlen-1\n",
    "            with autograd.record():\n",
    "                Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)\n",
    "                l = loss(Y_hat, Y_label, Y_vlen)\n",
    "            l.backward()\n",
    "            d2l.grad_clipping_gluon(model, 5, ctx)\n",
    "            num_tokens = Y_vlen.sum().asscalar()\n",
    "            trainer.step(num_tokens)\n",
    "            l_sum += l.sum().asscalar()\n",
    "            num_tokens_sum += num_tokens\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"epoch %d, loss %.3f, time %.1f sec\" % (\n",
    "                epoch, l_sum/num_tokens_sum, time.time()-tic))\n",
    "            tic = time.time()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 0.120, time 10.2 sec\n",
      "epoch 100, loss 0.066, time 10.4 sec\n",
      "epoch 150, loss 0.041, time 10.3 sec\n",
      "epoch 200, loss 0.031, time 10.3 sec\n",
      "epoch 250, loss 0.028, time 10.0 sec\n",
      "epoch 300, loss 0.025, time 9.5 sec\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_examples, max_len = 64, 1e3, 10\n",
    "lr, num_epochs, ctx = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "src_vocab, tgt_vocab, train_iter = d2l.load_data_nmt(\n",
    "    batch_size, max_len, num_examples)\n",
    "encoder = Seq2SeqEncoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqDecoder(\n",
    "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = d2l.EncoderDecoder(encoder, decoder)\n",
    "train_ch7(model, train_iter, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    }
   },
   "outputs": [],
   "source": [
    "def translate_ch7(model, src_sentence, src_vocab, tgt_vocab, max_len, ctx):\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')]\n",
    "    src_len = len(src_tokens)\n",
    "    if src_len < max_len:\n",
    "        src_tokens += [src_vocab.pad] * (max_len - src_len)\n",
    "    enc_X = nd.array(src_tokens, ctx=ctx)\n",
    "    enc_valid_length = nd.array([src_len], ctx=ctx)\n",
    "    # use expand_dim to add the batch_size dimension.\n",
    "    enc_outputs = model.encoder(enc_X.expand_dims(axis=0), enc_valid_length)\n",
    "    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)\n",
    "    dec_X = nd.array([tgt_vocab.bos], ctx=ctx).expand_dims(axis=0)\n",
    "    predict_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        Y, dec_state = model.decoder(dec_X, dec_state)\n",
    "        # The token with highest score is used as the next time step input. \n",
    "        dec_X = Y.argmax(axis=2)\n",
    "        py = dec_X.squeeze(axis=0).astype('int32').asscalar()\n",
    "        if py == tgt_vocab.eos:\n",
    "            break\n",
    "        predict_tokens.append(py)\n",
    "    return ' '.join(tgt_vocab.to_tokens(predict_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try several examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go . => va !\n",
      "Wow ! => <unk> !\n",
      "I'm OK . => je vais bien .\n",
      "I won ! => je l'ai emportÃ© !\n"
     ]
    }
   ],
   "source": [
    "for sentence in ['Go .', 'Wow !', \"I'm OK .\", 'I won !']:\n",
    "    print(sentence + ' => ' + translate_ch7(\n",
    "        model, sentence, src_vocab, tgt_vocab, max_len, ctx))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
